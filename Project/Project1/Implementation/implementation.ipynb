{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Space for MATH280 Proj. 1 \n",
    "### Author: Henry Yin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed python module for file reading\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tones_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a text file and extract tones from numbered pinyin syllables.\n",
    "    Each tone is represented as an integer (1-5) based on numbered pinyin syllables.\n",
    "    \"\"\"\n",
    "    tones = []\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} not found. Please check the file path and try again.\")\n",
    "        return []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line_tones = [int(word[-1]) for word in line.split() if word[-1].isdigit()]\n",
    "            tones.append(line_tones)\n",
    "    return tones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 1: Log-likelihood Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef construct_markov_matrix(tones_list, num_states=5):\\n    transition_counts = sa.Matrix(sa.SR, num_states, num_states, 1)  # Laplace smoothing (start with 1)\\n\\n    # Initialize with zeros\\n    transition_counts = sa.Matrix(sa.SR, num_states, num_states, 0)  \\n\\n    for tones in tones_list:\\n        for i in range(len(tones) - 1):\\n            current_tone = tones[i] - 1  # Adjusting to 0-based index\\n            next_tone = tones[i + 1] - 1  # Adjusting to 0-based index\\n            transition_counts[current_tone, next_tone] += 1\\n\\n    for i in range(num_states):\\n        row_sum = sum(transition_counts[i, j] for j in range(num_states))\\n        if row_sum > 0:\\n            for j in range(num_states):\\n                transition_counts[i, j] /= row_sum  # Normalize the row\\n\\n    return transition_counts\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sage.all as sa\n",
    "def construct_markov_matrix(tones_list, num_states=4):\n",
    "    \"\"\"\n",
    "    Create a SageMath Markov matrix for a given list of tone sequences.\n",
    "    NOTE: The matrix is normalized so that each row sums to 1, which is a bit differ to out definition in the class\n",
    "    \"\"\"\n",
    "    # Initialize with zeros\n",
    "    transition_counts = sa.Matrix(sa.SR, num_states, num_states, 0)  \n",
    "\n",
    "    for tones in tones_list:\n",
    "        for i in range(len(tones) - 1):\n",
    "            current_tone = tones[i] - 1  # Adjusting to 0-based index\n",
    "            next_tone = tones[i + 1] - 1  \n",
    "            transition_counts[current_tone, next_tone] += 1\n",
    "\n",
    "    for i in range(num_states):\n",
    "        row_sum = sum(transition_counts[i, j] for j in range(num_states))\n",
    "        if row_sum > 0:\n",
    "            for j in range(num_states):\n",
    "                transition_counts[i, j] /= row_sum  # Normalize the row\n",
    "\n",
    "    return transition_counts\n",
    "\n",
    "# Refined Version adding Laplace Smoothing for better performance in prediction\n",
    "'''\n",
    "def construct_markov_matrix(tones_list, num_states=5):\n",
    "    transition_counts = sa.Matrix(sa.SR, num_states, num_states, 1)  # Laplace smoothing (start with 1)\n",
    "\n",
    "    # Initialize with zeros\n",
    "    transition_counts = sa.Matrix(sa.SR, num_states, num_states, 0)  \n",
    "\n",
    "    for tones in tones_list:\n",
    "        for i in range(len(tones) - 1):\n",
    "            current_tone = tones[i] - 1  # Adjusting to 0-based index\n",
    "            next_tone = tones[i + 1] - 1  # Adjusting to 0-based index\n",
    "            transition_counts[current_tone, next_tone] += 1\n",
    "\n",
    "    for i in range(num_states):\n",
    "        row_sum = sum(transition_counts[i, j] for j in range(num_states))\n",
    "        if row_sum > 0:\n",
    "            for j in range(num_states):\n",
    "                transition_counts[i, j] /= row_sum  # Normalize the row\n",
    "\n",
    "    return transition_counts\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1 - Calculating the Log-liklihood of Markov Matrices\n",
    "\n",
    "from sage.all import log\n",
    "def compute_log_likelihood(matrix, test_tones):\n",
    "    \"\"\"\n",
    "    Calculate the log-likelihood of a sequence of tones given a SageMath Markov matrix.\n",
    "    \"\"\"\n",
    "    log_likelihood = 0\n",
    "    for i in range(len(test_tones) - 1):\n",
    "        current_state = test_tones[i] - 1\n",
    "        next_state = test_tones[i + 1] - 1\n",
    "        probability = matrix[current_state, next_state]\n",
    "        if probability > 0:\n",
    "            log_likelihood += log(probability)\n",
    "        else:\n",
    "            # Log(0) is -infinity\n",
    "            log_likelihood += float('-inf')  \n",
    "    return log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_author(test_tones_list, matrix_zhu, matrix_du):\n",
    "    total_likelihood_zhu = sum(compute_log_likelihood(matrix_zhu, tones) for tones in test_tones_list)\n",
    "    total_likelihood_du = sum(compute_log_likelihood(matrix_du, tones) for tones in test_tones_list)\n",
    "    \n",
    "    print(f\"Total log-likelihood for Zhu Shuzhen: {total_likelihood_zhu}\")\n",
    "    print(f\"Total log-likelihood for Du Fu: {total_likelihood_du}\")\n",
    "\n",
    "    if total_likelihood_zhu > total_likelihood_du:\n",
    "        return \"Zhu Shuzhen\"\n",
    "    else:\n",
    "        return \"Du Fu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_markov_matrix(matrix):\n",
    "    print(\"Markov Matrix (5-tone system):\")\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhu Shuzhen's Markov Matrix:\n",
      "[  3/10 47/190 29/190   3/10]\n",
      "[53/156    1/4  11/78   7/26]\n",
      "[35/103 27/103 15/103 26/103]\n",
      "[55/199 56/199 27/199 61/199]\n",
      "\n",
      "Du Fu's Markov Matrix:\n",
      "[   1/3 29/103 46/309 73/309]\n",
      "[88/279 73/279 49/279  23/93]\n",
      "[ 27/80 41/160   1/10 49/160]\n",
      "[69/236 37/118 21/118 51/236]\n",
      "Total log-likelihood for Zhu Shuzhen: 3*log(35/103) + 7*log(53/156) + 6*log(61/199) + 22*log(3/10) + 6*log(56/199) + 15*log(55/199) + 6*log(7/26) + 4*log(27/103) + 6*log(26/103) + 6*log(1/4) + 8*log(47/190) + 4*log(29/190) + 2*log(15/103) + 3*log(11/78) + 4*log(27/199)\n",
      "Total log-likelihood for Du Fu: 3*log(27/80) + 10*log(1/3) + 7*log(88/279) + 6*log(37/118) + 6*log(49/160) + 15*log(69/236) + 8*log(29/103) + 6*log(73/279) + 4*log(41/160) + 6*log(23/93) + 12*log(73/309) + 6*log(51/236) + 4*log(21/118) + 3*log(49/279) + 4*log(46/309) + 2*log(1/10)\n",
      "\n",
      "Predicted author for Zhu Shuzhen's test tones:  Zhu Shuzhen\n",
      "Total log-likelihood for Zhu Shuzhen: 10*log(35/103) + 9*log(53/156) + 5*log(61/199) + 19*log(3/10) + 6*log(56/199) + 7*log(55/199) + 9*log(7/26) + 4*log(27/103) + 3*log(26/103) + 3*log(1/4) + 18*log(47/190) + 2*log(29/190) + log(15/103) + 7*log(11/78) + 5*log(27/199)\n",
      "Total log-likelihood for Du Fu: 10*log(27/80) + 11*log(1/3) + 9*log(88/279) + 6*log(37/118) + 3*log(49/160) + 7*log(69/236) + 18*log(29/103) + 3*log(73/279) + 4*log(41/160) + 9*log(23/93) + 8*log(73/309) + 5*log(51/236) + 5*log(21/118) + 7*log(49/279) + 2*log(46/309) + log(1/10)\n",
      "Predicted author for Du Fu's test tones:  Du Fu\n"
     ]
    }
   ],
   "source": [
    "# Test Case:\n",
    " \n",
    "zsz_file = \"zsz.txt\"\n",
    "df_file = \"df.txt\"\n",
    "\n",
    "zsz_tones = extract_tones_from_file(zsz_file)\n",
    "df_tones = extract_tones_from_file(df_file)\n",
    "\n",
    "matrix_zhu = construct_markov_matrix(zsz_tones)\n",
    "matrix_du = construct_markov_matrix(df_tones)\n",
    "\n",
    "print(\"Zhu Shuzhen's Markov Matrix:\")\n",
    "print(matrix_zhu)\n",
    "print(\"\\nDu Fu's Markov Matrix:\")\n",
    "print(matrix_du)\n",
    "\n",
    "test_tones_zsz = zsz_tones[:20]  \n",
    "test_tones_df = df_tones[:20]   \n",
    "\n",
    "# Predict authorship based on multiple test sequences\n",
    "print(\"\\nPredicted author for Zhu Shuzhen's test tones: \", guess_author(test_tones_zsz, matrix_zhu, matrix_du))\n",
    "print(\"Predicted author for Du Fu's test tones: \", guess_author(test_tones_df, matrix_zhu, matrix_du))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhu Shuzhen's Markov Matrix:\n",
      "[  3/10 47/190 29/190   3/10]\n",
      "[53/156    1/4  11/78   7/26]\n",
      "[35/103 27/103 15/103 26/103]\n",
      "[55/199 56/199 27/199 61/199]\n",
      "\n",
      "Du Fu's Markov Matrix:\n",
      "[   1/3 29/103 46/309 73/309]\n",
      "[88/279 73/279 49/279  23/93]\n",
      "[ 27/80 41/160   1/10 49/160]\n",
      "[69/236 37/118 21/118 51/236]\n",
      "Total log-likelihood for Zhu Shuzhen: 3*log(35/103) + 5*log(53/156) + 4*log(61/199) + 3*log(3/10) + 6*log(56/199) + 3*log(55/199) + 2*log(7/26) + 5*log(26/103) + 5*log(1/4) + 3*log(47/190) + 4*log(29/190) + 2*log(15/103) + 2*log(11/78) + log(27/199)\n",
      "Total log-likelihood for Du Fu: 3*log(27/80) + log(1/3) + 5*log(88/279) + 6*log(37/118) + 5*log(49/160) + 3*log(69/236) + 3*log(29/103) + 5*log(73/279) + 2*log(23/93) + 2*log(73/309) + 4*log(51/236) + log(21/118) + 2*log(49/279) + 4*log(46/309) + 2*log(1/10)\n",
      "\n",
      "Predicted author for Zhu Shuzhen's test tones:  Zhu Shuzhen\n"
     ]
    }
   ],
   "source": [
    "# Formal Test Case Implementation\n",
    "zsz_file = \"zsz.txt\"\n",
    "zsz_test_file = \"zsz-test.txt\"\n",
    "df_file = \"df.txt\"\n",
    "df_test_file = \"\"\n",
    "\n",
    "zsz_tones = extract_tones_from_file(zsz_file)\n",
    "zsz_test_tones = extract_tones_from_file(zsz_test_file)\n",
    "df_tones = extract_tones_from_file(df_file)\n",
    "\n",
    "matrix_zhu = construct_markov_matrix(zsz_tones) \n",
    "matrix_du = construct_markov_matrix(df_tones)\n",
    "\n",
    "print(\"Zhu Shuzhen's Markov Matrix:\")\n",
    "print(matrix_zhu)\n",
    "print(\"\\nDu Fu's Markov Matrix:\")\n",
    "print(matrix_du)  \n",
    "\n",
    "# Predict authorship based on multiple test sequences\n",
    "print(\"\\nPredicted author for Zhu Shuzhen's test tones: \", guess_author(zsz_test_tones, matrix_zhu, matrix_du))\n",
    "# print(\"Predicted author for Du Fu's test tones: \", guess_author(test_tones_df, matrix_zhu, matrix_du))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 2: Cosine Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage.all as sa\n",
    "\n",
    "# Markov Matrix Implementation that the SUM of column matrix summed up to 1\n",
    "def construct_markov_matrix(tones_list, num_states=4):\n",
    "    transition_counts = sa.Matrix(sa.SR, num_states, num_states) \n",
    "\n",
    "    for tones in tones_list:\n",
    "        for i in range(len(tones) - 1):\n",
    "            current_tone = tones[i] - 1  # Convert tone to zero-based index\n",
    "            next_tone = tones[i + 1] - 1\n",
    "            transition_counts[current_tone, next_tone] += 1\n",
    "\n",
    "    # Normalize each column to sum to 1\n",
    "    for j in range(num_states):\n",
    "        col_sum = sum(transition_counts[i, j] for i in range(num_states))\n",
    "        if col_sum > 0:\n",
    "            for i in range(num_states):\n",
    "                transition_counts[i, j] /= col_sum\n",
    "\n",
    "    return transition_counts\n",
    "\n",
    "# Compute the Equilibrium Vector\n",
    "import numpy as np\n",
    "\n",
    "def equilibrium_vector(matrix):\n",
    "    \"\"\"\n",
    "    Compute the equilibrium vector using NumPy for numerical stability.\n",
    "    \"\"\"\n",
    "    # Convert SageMath matrix to NumPy array\n",
    "    matrix_np = np.array(matrix, dtype=float)\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(matrix_np)\n",
    "\n",
    "    # Find the eigenvector corresponding to the eigenvalue closest to 1\n",
    "    idx = np.argmin(np.abs(eigenvalues - 1))\n",
    "\n",
    "    equilibrium_vec = np.real(eigenvectors[:, idx])\n",
    "    equilibrium_vec /= equilibrium_vec.sum()\n",
    "\n",
    "    return equilibrium_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage.all as sa\n",
    "\n",
    "# Define Cosine Similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1, vec2 = sa.vector(vec1), sa.vector(vec2)\n",
    "    return vec1.dot_product(vec2) / (vec1.norm() * vec2.norm())\n",
    "\n",
    "# Define Euclidean Distance\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    return (sa.vector(vec1) - sa.vector(vec2)).norm()\n",
    "\n",
    "# Define Weighted Score Calculation\n",
    "# FIXME: ABORTED TRY\n",
    "def weighted_score(cos_sim, dist, alpha=0.5, beta=0.5):\n",
    "    return alpha * cos_sim + beta * (1 / (1 + dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author Prediction Calculation\n",
    "def predict_author(test_vector, vec_zhu, vec_du):\n",
    "    \"\"\"\n",
    "    Predict author using cosine similarity and Euclidean distance\n",
    "    between the test vector and the poets' equilibrium vectors separately.\n",
    "    \"\"\"\n",
    "    cos_sim_zhu = cosine_similarity(test_vector, vec_zhu)\n",
    "    cos_sim_du = cosine_similarity(test_vector, vec_du)\n",
    "\n",
    "    dist_zhu = euclidean_distance(test_vector, vec_zhu)\n",
    "    dist_du = euclidean_distance(test_vector, vec_du)\n",
    "\n",
    "\n",
    "    print(f\"Cosine Similarity with Zhu Shuzhen: {cos_sim_zhu}\")\n",
    "    print(f\"Cosine Similarity with Du Fu: {cos_sim_du}\")\n",
    "    print(f\"Euclidean Distance to Zhu Shuzhen: {dist_zhu}\")\n",
    "    print(f\"Euclidean Distance to Du Fu: {dist_du}\")\n",
    "\n",
    "    cos_prediction = \"Zhu Shuzhen\" if cos_sim_zhu > cos_sim_du else \"Du Fu\"\n",
    "    dist_prediction = \"Zhu Shuzhen\" if dist_zhu < dist_du else \"Du Fu\"\n",
    "\n",
    "    return cos_prediction, dist_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug Usage Tool Base \n",
    "\n",
    "def debug_matrix(matrix, name=\"Markov Matrix\"):\n",
    "\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(matrix)\n",
    "    print(f\"Column sums: {[sum(matrix.column(j)) for j in range(matrix.ncols())]}\")\n",
    "    try:\n",
    "        eigenvalues = matrix.eigenvalues()\n",
    "        print(f\"Eigenvalues: {eigenvalues}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing eigenvalues: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zhu Shuzhen's Markov Matrix:\n",
      "[57/200 47/169  29/93  19/62]\n",
      "[53/200   3/13  22/93   7/31]\n",
      "[  7/40 27/169   5/31  13/93]\n",
      "[ 11/40 56/169   9/31 61/186]\n",
      "Column sums: [1, 1, 1, 1]\n",
      "Eigenvalues: [-1/1450800*(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3)*(I*sqrt(3) + 1) + 41631431/1450800*(-I*sqrt(3) + 1)/(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3) + 1213/725400, -1/1450800*(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3)*(-I*sqrt(3) + 1) + 41631431/1450800*(I*sqrt(3) + 1)/(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3) + 1213/725400, 1/725400*(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3) - 41631431/725400/(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3) + 1213/725400, 1]\n",
      "\n",
      "Du Fu's Markov Matrix:\n",
      "[103/314  87/275  46/153  73/242]\n",
      "[ 44/157  73/275  49/153  69/242]\n",
      "[ 27/157  41/275  16/153  49/242]\n",
      "[ 69/314  74/275   14/51  51/242]\n",
      "Column sums: [1, 1, 1, 1]\n",
      "Eigenvalues: [-1/871962300*(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3)*(I*sqrt(3) + 1) - 32162449095694/217990575*(-I*sqrt(3) + 1)/(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3) - 6626987/217990575, -1/871962300*(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3)*(-I*sqrt(3) + 1) - 32162449095694/217990575*(I*sqrt(3) + 1)/(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3) - 6626987/217990575, 1/435981150*(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3) + 64324898191388/217990575/(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3) - 6626987/217990575, 1]\n",
      "\n",
      "Predicted author for Zhu Shuzhen's test tones:\n",
      "Cosine Similarity with Zhu Shuzhen: 0.9957655310799903\n",
      "Cosine Similarity with Du Fu: 0.9829425515401654\n",
      "Euclidean Distance to Zhu Shuzhen: 0.048189408347052154\n",
      "Euclidean Distance to Du Fu: 0.09582799253252247\n",
      "Cosine Similarity Prediction: Zhu Shuzhen\n",
      "Euclidean Distance Prediction: Zhu Shuzhen\n",
      "\n",
      "Predicted author for Du Fu's test tones:\n",
      "Cosine Similarity with Zhu Shuzhen: 0.9772365410769844\n",
      "Cosine Similarity with Du Fu: 0.9958879756926242\n",
      "Euclidean Distance to Zhu Shuzhen: 0.11016590075306289\n",
      "Euclidean Distance to Du Fu: 0.0470484668028332\n",
      "Cosine Similarity Prediction: Du Fu\n",
      "Euclidean Distance Prediction: Du Fu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Paths for input texts\\nzsz_file = \"zsz.txt\"\\ndf_file = \"df.txt\"\\n\\n# Extract tones from both files\\nzsz_tones = extract_tones_from_file(zsz_file)\\ndf_tones = extract_tones_from_file(df_file)\\n\\nfiltered_zsz_tones = [seq for seq in zsz_tones if seq]\\nfiltered_df_tones = [seq for seq in df_tones if seq]\\n\\nmatrix_zhu = construct_markov_matrix(filtered_zsz_tones)\\nmatrix_du = construct_markov_matrix(filtered_df_tones)\\n\\ndebug_matrix(matrix_zhu, \"Zhu Shuzhen\\'s Markov Matrix\")\\ndebug_matrix(matrix_du, \"Du Fu\\'s Markov Matrix\")\\n\\n# Compute equilibrium vectors using the NumPy-based method\\ntry:\\n    vec_zhu = equilibrium_vector(matrix_zhu)\\n    vec_du = equilibrium_vector(matrix_du)\\nexcept ValueError as e:\\n    print(f\"Error computing equilibrium vector: {e}\")\\n    exit()\\n\\n# Multiple Sequences Prediction\\nprint(\"\\nPredicted author for Zhu Shuzhen\\'s test tones:\",\\n      predict_author(filtered_zsz_tones[:3], vec_zhu, vec_du))\\nprint(\"Predicted author for Du Fu\\'s test tones:\",\\n      predict_author(filtered_df_tones[:3], vec_zhu, vec_du))\\n\\n# Single Sequence Prediction\\nprint(\"\\nPredicted author for a single Zhu Shuzhen sequence:\",\\n      predict_author([filtered_zsz_tones[0]], vec_zhu, vec_du))\\nprint(\"Predicted author for a single Du Fu sequence:\",\\n      predict_author([filtered_df_tones[0]], vec_zhu, vec_du))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample Test Case\n",
    "zsz_file = \"zsz.txt\"\n",
    "df_file = \"df.txt\"\n",
    "\n",
    "zsz_tones = extract_tones_from_file(zsz_file)\n",
    "df_tones = extract_tones_from_file(df_file)\n",
    "\n",
    "filtered_zsz_tones = [seq for seq in zsz_tones if seq]\n",
    "filtered_df_tones = [seq for seq in df_tones if seq]\n",
    "\n",
    "matrix_zhu = construct_markov_matrix(filtered_zsz_tones)\n",
    "matrix_du = construct_markov_matrix(filtered_df_tones)\n",
    "\n",
    "debug_matrix(matrix_zhu, \"Zhu Shuzhen's Markov Matrix\")\n",
    "debug_matrix(matrix_du, \"Du Fu's Markov Matrix\")\n",
    "\n",
    "try:\n",
    "    vec_zhu = equilibrium_vector(matrix_zhu)\n",
    "    vec_du = equilibrium_vector(matrix_du)\n",
    "except ValueError as e:\n",
    "    print(f\"Error computing equilibrium vector: {e}\")\n",
    "    exit()\n",
    "\n",
    "test_vector_zsz = equilibrium_vector(construct_markov_matrix(zsz_tones[:20]))\n",
    "test_vector_df = equilibrium_vector(construct_markov_matrix(df_tones[:20]))\n",
    "\n",
    "print(\"\\nPredicted author for Zhu Shuzhen's test tones:\")\n",
    "cos_pred, dist_pred = predict_author(test_vector_zsz, vec_zhu, vec_du)\n",
    "print(f\"Cosine Similarity Prediction: {cos_pred}\")\n",
    "print(f\"Euclidean Distance Prediction: {dist_pred}\")\n",
    "\n",
    "print(\"\\nPredicted author for Du Fu's test tones:\")\n",
    "cos_pred, dist_pred = predict_author(test_vector_df, vec_zhu, vec_du)\n",
    "print(f\"Cosine Similarity Prediction: {cos_pred}\")\n",
    "print(f\"Euclidean Distance Prediction: {dist_pred}\")\n",
    "\n",
    "'''\n",
    "# Paths for input texts\n",
    "zsz_file = \"zsz.txt\"\n",
    "df_file = \"df.txt\"\n",
    "\n",
    "# Extract tones from both files\n",
    "zsz_tones = extract_tones_from_file(zsz_file)\n",
    "df_tones = extract_tones_from_file(df_file)\n",
    "\n",
    "filtered_zsz_tones = [seq for seq in zsz_tones if seq]\n",
    "filtered_df_tones = [seq for seq in df_tones if seq]\n",
    "\n",
    "matrix_zhu = construct_markov_matrix(filtered_zsz_tones)\n",
    "matrix_du = construct_markov_matrix(filtered_df_tones)\n",
    "\n",
    "debug_matrix(matrix_zhu, \"Zhu Shuzhen's Markov Matrix\")\n",
    "debug_matrix(matrix_du, \"Du Fu's Markov Matrix\")\n",
    "\n",
    "# Compute equilibrium vectors using the NumPy-based method\n",
    "try:\n",
    "    vec_zhu = equilibrium_vector(matrix_zhu)\n",
    "    vec_du = equilibrium_vector(matrix_du)\n",
    "except ValueError as e:\n",
    "    print(f\"Error computing equilibrium vector: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Multiple Sequences Prediction\n",
    "print(\"\\nPredicted author for Zhu Shuzhen's test tones:\",\n",
    "      predict_author(filtered_zsz_tones[:3], vec_zhu, vec_du))\n",
    "print(\"Predicted author for Du Fu's test tones:\",\n",
    "      predict_author(filtered_df_tones[:3], vec_zhu, vec_du))\n",
    "\n",
    "# Single Sequence Prediction\n",
    "print(\"\\nPredicted author for a single Zhu Shuzhen sequence:\",\n",
    "      predict_author([filtered_zsz_tones[0]], vec_zhu, vec_du))\n",
    "print(\"Predicted author for a single Du Fu sequence:\",\n",
    "      predict_author([filtered_df_tones[0]], vec_zhu, vec_du))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equilibrium Vector for Zhu Shuzhen's Matrix:\n",
      "[0.29418287 0.24023142 0.15834941 0.3072363 ]\n",
      "Equilibrium Vector for Du Fu's Matrix:\n",
      "[0.31394412 0.28370395 0.16190486 0.24044708]\n"
     ]
    }
   ],
   "source": [
    "print(\"Equilibrium Vector for Zhu Shuzhen's Matrix:\")\n",
    "print(vec_zhu)\n",
    "print(\"Equilibrium Vector for Du Fu's Matrix:\")\n",
    "print(vec_du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhu Shuzhen's Markov Matrix:\n",
      "[57/200 47/169  29/93  19/62]\n",
      "[53/200   3/13  22/93   7/31]\n",
      "[  7/40 27/169   5/31  13/93]\n",
      "[ 11/40 56/169   9/31 61/186]\n",
      "Du Fu's Markov Matrix:\n",
      "[103/314  87/275  46/153  73/242]\n",
      "[ 44/157  73/275  49/153  69/242]\n",
      "[ 27/157  41/275  16/153  49/242]\n",
      "[ 69/314  74/275   14/51  51/242]\n"
     ]
    }
   ],
   "source": [
    "print(\"Zhu Shuzhen's Markov Matrix:\")\n",
    "print(matrix_zhu)\n",
    "print(\"Du Fu's Markov Matrix:\")\n",
    "print(matrix_du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zhu Shuzhen's Markov Matrix:\n",
      "[57/200 47/169  29/93  19/62]\n",
      "[53/200   3/13  22/93   7/31]\n",
      "[  7/40 27/169   5/31  13/93]\n",
      "[ 11/40 56/169   9/31 61/186]\n",
      "Column sums: [1, 1, 1, 1]\n",
      "Eigenvalues: [-1/1450800*(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3)*(I*sqrt(3) + 1) + 41631431/1450800*(-I*sqrt(3) + 1)/(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3) + 1213/725400, -1/1450800*(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3)*(-I*sqrt(3) + 1) + 41631431/1450800*(I*sqrt(3) + 1)/(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3) + 1213/725400, 1/725400*(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3) - 41631431/725400/(900*sqrt(117109835103492073)*sqrt(130) + 3501358455997)^(1/3) + 1213/725400, 1]\n",
      "\n",
      "Du Fu's Markov Matrix:\n",
      "[103/314  87/275  46/153  73/242]\n",
      "[ 44/157  73/275  49/153  69/242]\n",
      "[ 27/157  41/275  16/153  49/242]\n",
      "[ 69/314  74/275   14/51  51/242]\n",
      "Column sums: [1, 1, 1, 1]\n",
      "Eigenvalues: [-1/871962300*(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3)*(I*sqrt(3) + 1) - 32162449095694/217990575*(-I*sqrt(3) + 1)/(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3) - 6626987/217990575, -1/871962300*(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3)*(-I*sqrt(3) + 1) - 32162449095694/217990575*(I*sqrt(3) + 1)/(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3) - 6626987/217990575, 1/435981150*(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3) + 64324898191388/217990575/(59451975*sqrt(346018751526005953203981017) + 1830920369425363455101)^(1/3) - 6626987/217990575, 1]\n",
      "\n",
      "Predicted author for Zhu Shuzhen's test tones:\n",
      "Cosine Similarity with Zhu Shuzhen: 0.5728528390325099\n",
      "Cosine Similarity with Du Fu: 0.612084042064026\n",
      "Euclidean Distance to Zhu Shuzhen: 0.8218014556290012\n",
      "Euclidean Distance to Du Fu: 0.7969871938136044\n",
      "Cosine Similarity Prediction: Du Fu\n",
      "Euclidean Distance Prediction: Du Fu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\nPredicted author for Du Fu\\'s test tones:\")\\ncos_pred, dist_pred = predict_author(test_vector_df, vec_zhu, vec_du)\\nprint(f\"Cosine Similarity Prediction: {cos_pred}\")\\nprint(f\"Euclidean Distance Prediction: {dist_pred}\")\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formal Test Case Implementaion: \n",
    "zsz_file = \"zsz.txt\"\n",
    "zsz_file_test = \"zsz-test.txt\"\n",
    "df_file = \"df.txt\"\n",
    "\n",
    "zsz_tones = extract_tones_from_file(zsz_file)\n",
    "df_tones = extract_tones_from_file(df_file)\n",
    "\n",
    "filtered_zsz_tones = [seq for seq in zsz_tones if seq]\n",
    "filtered_df_tones = [seq for seq in df_tones if seq]\n",
    "\n",
    "matrix_zhu = construct_markov_matrix(filtered_zsz_tones)\n",
    "matrix_du = construct_markov_matrix(filtered_df_tones)\n",
    "\n",
    "debug_matrix(matrix_zhu, \"Zhu Shuzhen's Markov Matrix\")\n",
    "debug_matrix(matrix_du, \"Du Fu's Markov Matrix\")\n",
    "\n",
    "try:\n",
    "    vec_zhu = equilibrium_vector(matrix_zhu)\n",
    "    vec_du = equilibrium_vector(matrix_du)\n",
    "except ValueError as e:\n",
    "    print(f\"Error computing equilibrium vector: {e}\")\n",
    "    exit()\n",
    "\n",
    "test_vector_zsz = equilibrium_vector(construct_markov_matrix(zsz_file_test))\n",
    "# test_vector_df = equilibrium_vector(construct_markov_matrix(df_tones[:20]))\n",
    "\n",
    "print(\"\\nPredicted author for Zhu Shuzhen's test tones:\")\n",
    "cos_pred, dist_pred = predict_author(test_vector_zsz, vec_zhu, vec_du)\n",
    "print(f\"Cosine Similarity Prediction: {cos_pred}\")\n",
    "print(f\"Euclidean Distance Prediction: {dist_pred}\")\n",
    "\n",
    "'''\n",
    "print(\"\\nPredicted author for Du Fu's test tones:\")\n",
    "cos_pred, dist_pred = predict_author(test_vector_df, vec_zhu, vec_du)\n",
    "print(f\"Cosine Similarity Prediction: {cos_pred}\")\n",
    "print(f\"Euclidean Distance Prediction: {dist_pred}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Strategy: Vector Norm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_vector_infinity_norm_comparison(test_vector, vec_zhu, vec_du):\n",
    "    \"\"\"\n",
    "    Baseline strategy: Compare the infinity norm (max absolute difference) between the test equilibrium vector\n",
    "    and the poets' equilibrium vectors. Predict the author with the smaller norm.\n",
    "    \"\"\"\n",
    "    # Convert vectors to NumPy arrays if necessary\n",
    "    test_vector = np.array(test_vector)\n",
    "    vec_zhu = np.array(vec_zhu)\n",
    "    vec_du = np.array(vec_du)\n",
    "\n",
    "    # Compute the infinity norm differences (maximum absolute difference)\n",
    "    norm_diff_zhu = np.max(np.abs(test_vector - vec_zhu))  # Infinity norm for Zhu Shuzhen\n",
    "    norm_diff_du = np.max(np.abs(test_vector - vec_du))    # Infinity norm for Du Fu\n",
    "\n",
    "    # Print infinity norm differences for verification\n",
    "    print(f\"Infinity Norm Difference with Zhu Shuzhen: {norm_diff_zhu}\")\n",
    "    print(f\"Infinity Norm Difference with Du Fu: {norm_diff_du}\")\n",
    "\n",
    "    # Predict the author based on which infinity norm difference is smaller\n",
    "    return \"Zhu Shuzhen\" if norm_diff_zhu < norm_diff_du else \"Du Fu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Infinity Norm Prediction for Zhu Shuzhen's test tones:\n",
      "Infinity Norm Difference with Zhu Shuzhen: 0.20931363136794695\n",
      "Infinity Norm Difference with Du Fu: 0.18955238809187513\n",
      "Baseline Infinity Norm Prediction: Du Fu\n",
      "\n",
      "Baseline Infinity Norm Prediction for Du Fu's test tones:\n",
      "Infinity Norm Difference with Zhu Shuzhen: 0.19672621878053476\n",
      "Infinity Norm Difference with Du Fu: 0.17696497550446294\n",
      "Baseline Infinity Norm Prediction: Du Fu\n"
     ]
    }
   ],
   "source": [
    "# Example test case: Predict using infinity norm-based baseline strategy\n",
    "\n",
    "zsz_file = \"zsz.txt\"\n",
    "zsz_file_test = \"zsz-test.txt\"\n",
    "df_file = \"df.txt\"\n",
    "\n",
    "zsz_tones = extract_tones_from_file(zsz_file)\n",
    "df_tones = extract_tones_from_file(df_file)\n",
    "\n",
    "filtered_zsz_tones = [seq for seq in zsz_tones if seq]\n",
    "filtered_df_tones = [seq for seq in df_tones if seq]\n",
    "\n",
    "matrix_zhu = construct_markov_matrix(filtered_zsz_tones)\n",
    "matrix_du = construct_markov_matrix(filtered_df_tones)\n",
    "\n",
    "test_vector_zsz = equilibrium_vector(construct_markov_matrix(zsz_tones[:3]))\n",
    "test_vector_df = equilibrium_vector(construct_markov_matrix(df_tones[:3]))\n",
    "\n",
    "print(\"\\nBaseline Infinity Norm Prediction for Zhu Shuzhen's test tones:\")\n",
    "baseline_infinity_norm_prediction = baseline_vector_infinity_norm_comparison(test_vector_zsz, vec_zhu, vec_du)\n",
    "print(f\"Baseline Infinity Norm Prediction: {baseline_infinity_norm_prediction}\")\n",
    "\n",
    "print(\"\\nBaseline Infinity Norm Prediction for Du Fu's test tones:\")\n",
    "baseline_infinity_norm_prediction = baseline_vector_infinity_norm_comparison(test_vector_df, vec_zhu, vec_du)\n",
    "print(f\"Baseline Infinity Norm Prediction: {baseline_infinity_norm_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Infinity Norm Prediction for Zhu Shuzhen's test tones:\n",
      "Infinity Norm Difference with Zhu Shuzhen: 0.07692068226362686\n",
      "Infinity Norm Difference with Du Fu: 0.09668192553969868\n",
      "Baseline Infinity Norm Prediction: Zhu Shuzhen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\nBaseline Infinity Norm Prediction for Du Fu\\'s test tones:\")\\nbaseline_infinity_norm_prediction = baseline_vector_infinity_norm_comparison(test_vector_df, vec_zhu, vec_du)\\nprint(f\"Baseline Infinity Norm Prediction: {baseline_infinity_norm_prediction}\")\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formal Test case: \n",
    "zsz_file = \"zsz.txt\"\n",
    "zsz_file_test = \"zsz-test.txt\"\n",
    "df_file = \"df.txt\"\n",
    "\n",
    "zsz_tones = extract_tones_from_file(zsz_file)\n",
    "zsz_test_tones = extract_tones_from_file(zsz_file_test)\n",
    "df_tones = extract_tones_from_file(df_file)\n",
    "\n",
    "filtered_zsz_tones = [seq for seq in zsz_tones if seq]\n",
    "filtered_zsz_tones_test = [seq for seq in zsz_test_tones if seq]\n",
    "filtered_df_tones = [seq for seq in df_tones if seq]\n",
    "\n",
    "matrix_zhu = construct_markov_matrix(filtered_zsz_tones)\n",
    "matrix_zhu_test = construct_markov_matrix(filtered_zsz_tones_test)\n",
    "matrix_du = construct_markov_matrix(filtered_df_tones)\n",
    "\n",
    "test_vector_zsz = equilibrium_vector(matrix_zhu_test)\n",
    "\n",
    "print(\"\\nBaseline Infinity Norm Prediction for Zhu Shuzhen's test tones:\")\n",
    "baseline_infinity_norm_prediction = baseline_vector_infinity_norm_comparison(test_vector_zsz, vec_zhu, vec_du)\n",
    "print(f\"Baseline Infinity Norm Prediction: {baseline_infinity_norm_prediction}\")\n",
    "\n",
    "'''\n",
    "print(\"\\nBaseline Infinity Norm Prediction for Du Fu's test tones:\")\n",
    "baseline_infinity_norm_prediction = baseline_vector_infinity_norm_comparison(test_vector_df, vec_zhu, vec_du)\n",
    "print(f\"Baseline Infinity Norm Prediction: {baseline_infinity_norm_prediction}\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
